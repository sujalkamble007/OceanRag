"""
run_evaluation.py â€” Phase 4 entry point.
Runs testset generation, experiment evaluation, export, and leaderboard.
"""

from pathlib import Path

from config import (
    QDRANT_COLLECTION_NAME, DEFAULT_CHUNK_CONFIG,
    DEFAULT_EMBEDDING_CONFIG, DEFAULT_TOP_K, OUTPUT_DIR, DOCS_DIR,
)
import database
from document_loader import load_documents
from chunker import chunk_documents
from embedder import load_embedding_model
from qdrant_store import get_qdrant_client, get_collection_info
from testset_generator import generate_testset, load_testset, validate_testset
from experiment_runner import (
    run_single_experiment, run_quick_evaluation,
    run_full_experiment_matrix, EVAL_LLM_KEYS,
)
from results_exporter import (
    export_to_csv, print_leaderboard,
    print_metric_comparison_table, generate_chart_data,
)
from llm_handler import LLM_CONFIGS


def main():
    """Phase 4 pipeline: init â†’ testset â†’ evaluate â†’ export â†’ leaderboard."""

    print()
    print("=" * 60)
    print("  PHASE 4: EVALUATION MODULE")
    print("=" * 60)
    print()

    # â”€â”€â”€ Step 1: Initialize from Phase 1+2+3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("=" * 55)
    print("  STEP 1: INITIALIZE FROM PHASE 1 + 2 + 3")
    print("=" * 55)

    database.init_db(reset=False)

    client = get_qdrant_client()
    info = get_collection_info(client, QDRANT_COLLECTION_NAME)

    if info["vectors_count"] == 0:
        print("âŒ No vectors found in Qdrant. Run Phase 1 first (python main.py).")
        return None

    embedding_model = load_embedding_model(DEFAULT_EMBEDDING_CONFIG)

    print("\nğŸ“„ Loading documents for BM25 index...")
    docs = load_documents(DOCS_DIR)
    chunks = chunk_documents(docs, DEFAULT_CHUNK_CONFIG, OUTPUT_DIR)

    print("âœ… Phase 1+2+3 initialized")

    # â”€â”€â”€ Step 2: Database ready â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print()
    print("=" * 55)
    print("  STEP 2: DATABASE READY")
    print("=" * 55)
    print("  âœ… experiments table available")
    print("  âœ… qa_logs table available")

    # â”€â”€â”€ Step 3: Testset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print()
    print("=" * 55)
    print("  STEP 3: QA TESTSET")
    print("=" * 55)

    if Path("output/testset.csv").exists():
        df = load_testset()
    else:
        print("ğŸ”„ Generating testset using Groq (llama-3.1-8b-instant)...")
        df = generate_testset(docs, embedding_model)

    df = validate_testset(df)
    print(f"ğŸ“‹ Using {len(df)} questions for evaluation\n")

    # â”€â”€â”€ Step 4: Mode selection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("â•" * 50)
    print("  DeepRAG Evaluation Mode")
    print("â•" * 50)
    print("  1. Quick Eval  (3 retrievers Ã— 4 LLMs, default config) ~15 min")
    print("  2. Full Matrix (all combinations)                      ~2â€“4 hrs")
    print("  3. Single Run  (fastest sanity check)                  ~3 min")

    try:
        mode_input = input("Choose [1/2/3, default=1]: ").strip()
    except (EOFError, KeyboardInterrupt):
        print("\nğŸ‘‹ Exiting.")
        return None

    mode = mode_input if mode_input in ("1", "2", "3") else "1"

    results = []

    if mode == "1":
        # Quick evaluation
        results = run_quick_evaluation(
            df, client, QDRANT_COLLECTION_NAME,
            embedding_model, chunks,
        )

    elif mode == "2":
        # Full matrix
        results = run_full_experiment_matrix(df, client, docs)

    elif mode == "3":
        # Single run â€” fastest sanity check
        first_available = None
        for k in EVAL_LLM_KEYS:
            if k in LLM_CONFIGS:
                first_available = k
                break
        if not first_available:
            first_available = list(LLM_CONFIGS.keys())[0]

        config = {
            "chunk_config": DEFAULT_CHUNK_CONFIG,
            "embedding_config": DEFAULT_EMBEDDING_CONFIG,
            "retriever_type": "mmr",
            "llm_key": first_available,
            "top_k": DEFAULT_TOP_K,
            "collection_name": QDRANT_COLLECTION_NAME,
        }
        print(f"\n  â–¶ Single run: mmr | {LLM_CONFIGS[first_available]['name']} | k={DEFAULT_TOP_K}")
        result = run_single_experiment(config, df, client, chunks)
        if result:
            results = [result]

    if not results:
        print("âŒ No experiment results. Check API keys and configuration.")
        return None

    # â”€â”€â”€ Step 5: Export + Display â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print()
    print("=" * 55)
    print("  STEP 5: RESULTS")
    print("=" * 55)

    export_to_csv(results)
    print_leaderboard(results)
    print_metric_comparison_table(results)
    generate_chart_data(results)
    print("\nğŸ“ All outputs saved to output/")

    # â”€â”€â”€ Step 6: Show best config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print()
    best = database.get_best_config()
    if best:
        print("â•" * 50)
        print("  ğŸ† RECOMMENDED CONFIGURATION")
        print("â•" * 50)
        print(f"  Chunking    : {best.get('chunk_strategy', 'N/A')}")
        print(f"  Embedding   : {best.get('embedding_model', 'N/A')}")
        print(f"  Retriever   : {best.get('retriever_type', 'N/A')}")
        print(f"  LLM         : {best.get('llm_name', 'N/A')}")
        print(f"  Top-K       : {best.get('top_k', 'N/A')}")
        print(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print(f"  Precision@K : {best.get('precision_at_k', 'N/A')}")
        print(f"  Recall@K    : {best.get('recall_at_k', 'N/A')}")
        print(f"  Faithfulness: {best.get('faithfulness', 'N/A')}")
        print(f"  Latency     : {best.get('latency_seconds', 'N/A')}s")
        print(f"  Cost/Query  : FREE (Groq + HuggingFace)")
        print()

    print("ğŸ‰ Phase 4 Complete!")
    return results


if __name__ == "__main__":
    main()
